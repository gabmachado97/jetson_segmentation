{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conversor_fastai.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fUV96fG8isZK",
        "pOb1z6v_izoM",
        "V0tDuneVnZzJ",
        "WflB48l4jC0d"
      ],
      "toc_visible": true,
      "mount_file_id": "1cBCrVkDukQeaBhczmN5o1VP-pcT4sTER",
      "authorship_tag": "ABX9TyMPSm5c4E8weABN6mvwa6V+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabmachado97/jetson_segmentation/blob/main/conversor_fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUV96fG8isZK"
      },
      "source": [
        "## 1. Install packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saIwY3_MiJpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c59f4f-444b-43b6-905e-c34b258f3186"
      },
      "source": [
        "!pip3 install onnx\n",
        "!pip3 install onnxruntime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 215kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.1.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.9.0\n",
            "Collecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/f0/666d6e3ceaa276a54e728f9972732e058544cbb6a3e1a778a8d6f87132c1/onnxruntime-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (56.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Installing collected packages: onnxruntime\n",
            "Successfully installed onnxruntime-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOb1z6v_izoM"
      },
      "source": [
        "## 2. Convert fastai model to onnx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lni7IOgPWbYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c35cb44-92fc-4f45-f9bb-dc2bad404f98"
      },
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "from fastai.vision import *\n",
        "\n",
        "#rtk model accuracy\n",
        "def acc_rtk(input, target):\n",
        "    target = target.squeeze(1)\n",
        "    mask = target != 0\n",
        "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()\n",
        "\n",
        "\n",
        "path_pkl = '/content/drive/My Drive/Mestrado/Segmentação/'\n",
        "path_weights = '/content/drive/My Drive/Mestrado/Segmentação/data/images/models/stage-2-weights'\n",
        "learn = load_learner(path_pkl, 'export.pkl')\n",
        "learn.load(path_weights)\n",
        "model = learn.model\n",
        "\n",
        "# Create the right input shape (e.g. for an image)\n",
        "sample_batch_size = 1\n",
        "channel = 3\n",
        "height = 352\n",
        "width = 288\n",
        "dummy_input = torch.randn(sample_batch_size, channel, height, width).to('cuda')\n",
        "torch_out = model(dummy_input)\n",
        "\n",
        "torch.onnx.export(model, \n",
        "                  dummy_input, \n",
        "                  \"/content/drive/My Drive/Mestrado/Segmentação/convert_onnx/rtk_plus_resnet34.onnx\",\n",
        "                   verbose=True,\n",
        "                    export_params=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/vision/models/unet.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if ssh != up_out.shape[-2:]:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "graph(%input.1 : Float(1:304128, 3:101376, 352:288, 288:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.1.weight : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.1.bias : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.1.running_mean : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.1.running_var : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.3.0.0.weight : Float(1024:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.3.0.0.bias : Float(1024:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.3.1.0.weight : Float(512:9216, 1024:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.3.1.0.bias : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.shuf.conv.0.weight : Float(1024:512, 512:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.shuf.conv.0.bias : Float(1024:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.bn.weight : Float(256:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.bn.bias : Float(256:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.bn.running_mean : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.4.bn.running_var : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.4.conv1.0.weight : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.conv1.0.bias : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.conv2.0.weight : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.4.conv2.0.bias : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.shuf.conv.0.weight : Float(1024:512, 512:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.shuf.conv.0.bias : Float(1024:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.bn.weight : Float(128:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.bn.bias : Float(128:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.bn.running_mean : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.5.bn.running_var : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.5.conv1.0.weight : Float(384:3456, 384:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.conv1.0.bias : Float(384:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.conv2.0.weight : Float(384:3456, 384:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.5.conv2.0.bias : Float(384:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.shuf.conv.0.weight : Float(768:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.shuf.conv.0.bias : Float(768:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.bn.weight : Float(64:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.bn.bias : Float(64:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.bn.running_mean : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.6.bn.running_var : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.6.conv1.0.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.conv1.0.bias : Float(256:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.conv2.0.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.6.conv2.0.bias : Float(256:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.shuf.conv.0.weight : Float(512:256, 256:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.shuf.conv.0.bias : Float(512:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.bn.weight : Float(64:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.bn.bias : Float(64:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.bn.running_mean : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.7.bn.running_var : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %layers.7.conv1.0.weight : Float(96:1728, 192:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.conv1.0.bias : Float(96:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.conv2.0.weight : Float(96:864, 96:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.7.conv2.0.bias : Float(96:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.8.conv.0.weight : Float(384:96, 96:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.8.conv.0.bias : Float(384:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.10.layers.0.0.weight : Float(99:891, 99:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.10.layers.0.0.bias : Float(99:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.10.layers.1.0.weight : Float(99:891, 99:9, 3:3, 3:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.10.layers.1.0.bias : Float(99:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.11.0.weight : Float(13:99, 99:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
            "      %layers.11.0.bias : Float(13:1, requires_grad=1, device=cuda:0),\n",
            "      %477 : Float(64:147, 3:49, 7:7, 7:1, requires_grad=0, device=cuda:0),\n",
            "      %478 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %480 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %481 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %483 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %484 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %486 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %487 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %489 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %490 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %492 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %493 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %495 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %496 : Float(64:1, requires_grad=0, device=cuda:0),\n",
            "      %498 : Float(128:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %499 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %501 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %502 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %504 : Float(128:64, 64:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
            "      %505 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %507 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %508 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %510 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %511 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %513 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %514 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %516 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %517 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %519 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %520 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %522 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %523 : Float(128:1, requires_grad=0, device=cuda:0),\n",
            "      %525 : Float(256:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %526 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %528 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %529 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %531 : Float(256:128, 128:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
            "      %532 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %534 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %535 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %537 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %538 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %540 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %541 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %543 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %544 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %546 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %547 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %549 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %550 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %552 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %553 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %555 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %556 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %558 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %559 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %561 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %562 : Float(256:1, requires_grad=0, device=cuda:0),\n",
            "      %564 : Float(512:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %565 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %567 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %568 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %570 : Float(512:256, 256:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
            "      %571 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %573 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %574 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %576 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %577 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %579 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %580 : Float(512:1, requires_grad=0, device=cuda:0),\n",
            "      %582 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
            "      %583 : Float(512:1, requires_grad=0, device=cuda:0)):\n",
            "  %476 : Float(1:1622016, 64:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input.1, %477, %478)\n",
            "  %280 : Float(1:1622016, 64:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Relu(%476) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %281 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%280) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:586:0\n",
            "  %479 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%281, %480, %481)\n",
            "  %284 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%479) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %482 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%284, %483, %484)\n",
            "  %287 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Add(%482, %281)\n",
            "  %288 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%287) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %485 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%288, %486, %487)\n",
            "  %291 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%485) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %488 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%291, %489, %490)\n",
            "  %294 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Add(%488, %288)\n",
            "  %295 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%294) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %491 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%295, %492, %493)\n",
            "  %298 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%491) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %494 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%298, %495, %496)\n",
            "  %301 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Add(%494, %295)\n",
            "  %302 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%301) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %497 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%302, %498, %499)\n",
            "  %305 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%497) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %500 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %501, %502)\n",
            "  %503 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%302, %504, %505)\n",
            "  %310 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Add(%500, %503)\n",
            "  %311 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%310) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %506 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%311, %507, %508)\n",
            "  %314 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%506) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %509 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%314, %510, %511)\n",
            "  %317 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Add(%509, %311)\n",
            "  %318 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%317) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %512 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%318, %513, %514)\n",
            "  %321 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%512) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %515 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%321, %516, %517)\n",
            "  %324 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Add(%515, %318)\n",
            "  %325 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%324) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %518 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%325, %519, %520)\n",
            "  %328 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%518) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %521 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%328, %522, %523)\n",
            "  %331 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Add(%521, %325)\n",
            "  %332 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%331) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %524 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%332, %525, %526)\n",
            "  %335 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%524) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %527 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%335, %528, %529)\n",
            "  %530 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%332, %531, %532)\n",
            "  %340 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%527, %530)\n",
            "  %341 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%340) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %533 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%341, %534, %535)\n",
            "  %344 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%533) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %536 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%344, %537, %538)\n",
            "  %347 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%536, %341)\n",
            "  %348 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%347) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %539 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%348, %540, %541)\n",
            "  %351 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%539) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %542 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%351, %543, %544)\n",
            "  %354 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%542, %348)\n",
            "  %355 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%354) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %545 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%355, %546, %547)\n",
            "  %358 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%545) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %548 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%358, %549, %550)\n",
            "  %361 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%548, %355)\n",
            "  %362 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%361) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %551 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%362, %552, %553)\n",
            "  %365 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%551) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %554 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%365, %555, %556)\n",
            "  %368 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%554, %362)\n",
            "  %369 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%368) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %557 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%369, %558, %559)\n",
            "  %372 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%557) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %560 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%372, %561, %562)\n",
            "  %375 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Add(%560, %369)\n",
            "  %376 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%375) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %563 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%376, %564, %565)\n",
            "  %379 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%563) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %566 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%379, %567, %568)\n",
            "  %569 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%376, %570, %571)\n",
            "  %384 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Add(%566, %569)\n",
            "  %385 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%384) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %572 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%385, %573, %574)\n",
            "  %388 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%572) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %575 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%388, %576, %577)\n",
            "  %391 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Add(%575, %385)\n",
            "  %392 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%391) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %578 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%392, %579, %580)\n",
            "  %395 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%578) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %581 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%395, %582, %583)\n",
            "  %398 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Add(%581, %392)\n",
            "  %399 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%398) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %400 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%399, %layers.1.weight, %layers.1.bias, %layers.1.running_mean, %layers.1.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2058:0\n",
            "  %401 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%400) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %402 : Float(1:101376, 1024:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%401, %layers.3.0.0.weight, %layers.3.0.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %403 : Float(1:101376, 1024:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%402) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %404 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%403, %layers.3.1.0.weight, %layers.3.1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %405 : Float(1:50688, 512:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%404) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %406 : Float(1:101376, 1024:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%405, %layers.4.shuf.conv.0.weight, %layers.4.shuf.conv.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %407 : Float(1:101376, 1024:99, 11:9, 9:1, requires_grad=1, device=cuda:0) = onnx::Relu(%406) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %408 : Tensor = onnx::Constant[value=  -1  256    2    2   11    9 [ CPULongType{6} ]]()\n",
            "  %409 : Tensor = onnx::Reshape(%407, %408)\n",
            "  %410 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%409)\n",
            "  %411 : Tensor = onnx::Constant[value=  -1  256   22   18 [ CPULongType{4} ]]()\n",
            "  %412 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%410, %411) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py:46:0\n",
            "  %413 : Float(1:101376, 256:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%376, %layers.4.bn.weight, %layers.4.bn.bias, %layers.4.bn.running_mean, %layers.4.bn.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2058:0\n",
            "  %414 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%412, %413) # /usr/local/lib/python3.6/dist-packages/fastai/vision/models/unet.py:33:0\n",
            "  %415 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%414) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %416 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%415, %layers.4.conv1.0.weight, %layers.4.conv1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %417 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%416) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %418 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%417, %layers.4.conv2.0.weight, %layers.4.conv2.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %419 : Float(1:202752, 512:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%418) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %420 : Float(1:405504, 1024:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%419, %layers.5.shuf.conv.0.weight, %layers.5.shuf.conv.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %421 : Float(1:405504, 1024:396, 22:18, 18:1, requires_grad=1, device=cuda:0) = onnx::Relu(%420) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %422 : Tensor = onnx::Constant[value=  -1  256    2    2   22   18 [ CPULongType{6} ]]()\n",
            "  %423 : Tensor = onnx::Reshape(%421, %422)\n",
            "  %424 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%423)\n",
            "  %425 : Tensor = onnx::Constant[value=  -1  256   44   36 [ CPULongType{4} ]]()\n",
            "  %426 : Float(1:405504, 256:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%424, %425) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py:46:0\n",
            "  %427 : Float(1:202752, 128:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%332, %layers.5.bn.weight, %layers.5.bn.bias, %layers.5.bn.running_mean, %layers.5.bn.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2058:0\n",
            "  %428 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%426, %427) # /usr/local/lib/python3.6/dist-packages/fastai/vision/models/unet.py:33:0\n",
            "  %429 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%428) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %430 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%429, %layers.5.conv1.0.weight, %layers.5.conv1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %431 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%430) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %432 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%431, %layers.5.conv2.0.weight, %layers.5.conv2.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %433 : Float(1:608256, 384:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%432) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %434 : Float(1:1216512, 768:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%433, %layers.6.shuf.conv.0.weight, %layers.6.shuf.conv.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %435 : Float(1:1216512, 768:1584, 44:36, 36:1, requires_grad=1, device=cuda:0) = onnx::Relu(%434) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %436 : Tensor = onnx::Constant[value=  -1  192    2    2   44   36 [ CPULongType{6} ]]()\n",
            "  %437 : Tensor = onnx::Reshape(%435, %436)\n",
            "  %438 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%437)\n",
            "  %439 : Tensor = onnx::Constant[value=  -1  192   88   72 [ CPULongType{4} ]]()\n",
            "  %440 : Float(1:1216512, 192:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%438, %439) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py:46:0\n",
            "  %441 : Float(1:405504, 64:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%302, %layers.6.bn.weight, %layers.6.bn.bias, %layers.6.bn.running_mean, %layers.6.bn.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2058:0\n",
            "  %442 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%440, %441) # /usr/local/lib/python3.6/dist-packages/fastai/vision/models/unet.py:33:0\n",
            "  %443 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%442) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %444 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%443, %layers.6.conv1.0.weight, %layers.6.conv1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %445 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%444) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %446 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%445, %layers.6.conv2.0.weight, %layers.6.conv2.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %447 : Float(1:1622016, 256:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%446) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %448 : Float(1:3244032, 512:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%447, %layers.7.shuf.conv.0.weight, %layers.7.shuf.conv.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %449 : Float(1:3244032, 512:6336, 88:72, 72:1, requires_grad=1, device=cuda:0) = onnx::Relu(%448) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %450 : Tensor = onnx::Constant[value=  -1  128    2    2   88   72 [ CPULongType{6} ]]()\n",
            "  %451 : Tensor = onnx::Reshape(%449, %450)\n",
            "  %452 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%451)\n",
            "  %453 : Tensor = onnx::Constant[value=  -1  128  176  144 [ CPULongType{4} ]]()\n",
            "  %454 : Float(1:3244032, 128:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%452, %453) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py:46:0\n",
            "  %455 : Float(1:1622016, 64:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%280, %layers.7.bn.weight, %layers.7.bn.bias, %layers.7.bn.running_mean, %layers.7.bn.running_var) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2058:0\n",
            "  %456 : Float(1:4866048, 192:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%454, %455) # /usr/local/lib/python3.6/dist-packages/fastai/vision/models/unet.py:33:0\n",
            "  %457 : Float(1:4866048, 192:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Relu(%456) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %458 : Float(1:2433024, 96:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%457, %layers.7.conv1.0.weight, %layers.7.conv1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %459 : Float(1:2433024, 96:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Relu(%458) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %460 : Float(1:2433024, 96:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%459, %layers.7.conv2.0.weight, %layers.7.conv2.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %461 : Float(1:2433024, 96:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Relu(%460) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %462 : Float(1:9732096, 384:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%461, %layers.8.conv.0.weight, %layers.8.conv.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %463 : Float(1:9732096, 384:25344, 176:144, 144:1, requires_grad=1, device=cuda:0) = onnx::Relu(%462) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %464 : Tensor = onnx::Constant[value=  -1   96    2    2  176  144 [ CPULongType{6} ]]()\n",
            "  %465 : Tensor = onnx::Reshape(%463, %464)\n",
            "  %466 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%465)\n",
            "  %467 : Tensor = onnx::Constant[value=  -1   96  352  288 [ CPULongType{4} ]]()\n",
            "  %468 : Float(1:9732096, 96:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%466, %467) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py:46:0\n",
            "  %469 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%468, %input.1) # /usr/local/lib/python3.6/dist-packages/fastai/layers.py:150:0\n",
            "  %470 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%469, %layers.10.layers.0.0.weight, %layers.10.layers.0.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %471 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Relu(%470) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %472 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%471, %layers.10.layers.1.0.weight, %layers.10.layers.1.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %473 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Relu(%472) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1134:0\n",
            "  %474 : Float(1:10036224, 99:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Add(%473, %469) # /usr/local/lib/python3.6/dist-packages/fastai/layers.py:150:0\n",
            "  %475 : Float(1:1317888, 13:101376, 352:288, 288:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%474, %layers.11.0.weight, %layers.11.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  return (%475)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0tDuneVnZzJ"
      },
      "source": [
        "## 3. Optional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiIFHpV1maV"
      },
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"/content/drive/My Drive/Mestrado/Segmentação/convert_onnx/rtk_plus_resnet34.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Fi2N2W8Z-l"
      },
      "source": [
        "import onnxruntime\n",
        "import torch\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"/content/drive/My Drive/Mestrado/Segmentação/convert_onnx/rtk_resnet34.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WflB48l4jC0d"
      },
      "source": [
        "## Backup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3FPEsbFOrS_"
      },
      "source": [
        "learn = load_learner('/content/drive/My Drive/Mestrado/Segmentação/', 'export.pkl')\n",
        "learn.load('/content/drive/My Drive/Mestrado/Segmentação/data/images/models/stage-2-weights')\n",
        "model = learn.model\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}